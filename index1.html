<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Course Learning Reflections</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles1.css">
</head>
<body>
    <header>
        <h1>Course Learning Reflections</h1>
    </header>
    <main>
        <section>
            <h2>Kinds of Problems in Nature</h2>
            <p>Problems in nature often align with algorithmic approaches like <strong>iteration</strong>, <strong>recursion</strong>, and <strong>backtracking</strong>:</p>
            <ul>
                <li><em>Iteration</em> handles repetitive tasks efficiently, such as traversing arrays.</li>
                <li><em>Recursion</em> breaks problems into smaller subproblems, useful for tasks like solving the Fibonacci sequence or tree traversal.</li>
                <li><em>Backtracking</em> explores all possibilities systematically, suitable for optimization problems like the N-Queens puzzle.</li>
            </ul>
        </section>
        <section>
            <h2>Space and Time Efficiency</h2>
            <p>Space and time efficiency measure how well an algorithm utilizes resources. They are important because:</p>
            <ul>
                <li>Limited <strong>time</strong> ensures solutions are obtained quickly, crucial in real-world systems.</li>
                <li>Optimized <strong>space</strong> minimizes memory use, enabling algorithms to run on systems with constrained resources.</li>
            </ul>
            <p>The <strong>orders of growth</strong> (e.g., O(1), O(n), O(n²)) describe how an algorithm scales, helping us compare their efficiency for large inputs.</p>
        </section>
        <section>
            <h2>Takeaways from Design Principles (Chapter 2)</h2>
            <ul>
                <li><strong>Pruning:</strong> Eliminating unnecessary computations improves efficiency.</li>
                <li><strong>Hashing:</strong> Provides fast data retrieval by mapping keys to indices.</li>
                <li><strong>Union-Find:</strong> Simplifies handling of disjoint sets, useful in problems like Kruskal's MST.</li>
            </ul>
        </section>
        <section>
            <h2>Hierarchical Data and Tree Structures</h2>
            <p>Trees and their variants optimize data handling:</p>
            <ul>
                <li><strong>Binary Search Trees (BSTs):</strong> Enable efficient searching.</li>
                <li><strong>AVL Trees:</strong> Maintain balance, ensuring logarithmic time for operations.</li>
                <li><strong>Red-Black Trees:</strong> Offer faster insertion/deletion while being approximately balanced.</li>
                <li><strong>Heaps:</strong> Support priority queues efficiently.</li>
                <li><strong>Tries:</strong> Manage string data compactly, ideal for prefix-based searching.</li>
            </ul>
        </section>
        <section>
            <h2>Array Query Algorithms</h2>
            <p>Techniques like <strong>Segment Trees</strong> and <strong>Fenwick Trees</strong> enable fast range queries and updates. Applications include competitive programming tasks like range sum or minimum queries, where speed is critical.</p>
        </section>
        <section>
            <h2>Trees vs. Graphs</h2>
            <ul>
                <li><strong>Trees:</strong> Acyclic and connected, used for hierarchical data like file systems.</li>
                <li><strong>Graphs:</strong> Handle complex relationships, supporting cyclic and disconnected structures.</li>
            </ul>
            <p><strong>DFS</strong> explores deeply, while <strong>BFS</strong> ensures the shortest path in unweighted graphs.</p>
        </section>
        <section>
            <h2>Sorting and Searching Algorithms</h2>
            <ul>
                <li><strong>Sorting:</strong> Algorithms like <strong>Merge Sort</strong> (divide-and-conquer) and <strong>Heap Sort</strong> (priority queue) optimize data arrangement.</li>
                <li><strong>Searching:</strong> Techniques like <strong>Binary Search</strong> efficiently find elements in sorted arrays.</li>
            </ul>
        </section>
        <section>
            <h2>Graph Algorithms for Spanning Trees and Shortest Paths</h2>
            <ul>
                <li><strong>Prim's</strong> and <strong>Kruskal's:</strong> Build Minimum Spanning Trees, optimizing resource connections like road networks.</li>
                <li><strong>Dijkstra’s</strong> and <strong>Bellman-Ford:</strong> Find shortest paths, essential in navigation systems.</li>
            </ul>
        </section>
        <section>
            <h2>Reflections on Broader Questions</h2>
            <p>Key takeaways include:</p>
            <ul>
                <li><strong>Efficient Approaches:</strong> Assess problem constraints, scalability, and resource limits.</li>
                <li><strong>Balancing Conflicting Constraints:</strong> Prioritize speed vs. memory based on usage.</li>
                <li><strong>Adapting Solutions:</strong> For example, adapting BFS to find connected components in a graph.</li>
            </ul>
        </section>
    </main>
    <footer>
        <p>&copy; 2024 Created by Sushant</p>
    </footer>
</body>
</html>
