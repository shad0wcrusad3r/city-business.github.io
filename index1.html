<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Learning Reflections From The Course</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles1.css">
</head>
<body>
    <header>
        <h1>Learning Reflections From The Course</h1>
    </header>
    <main>
        <section>
            <h2>Types of Problems Found in Nature</h2>
            <p>Natural problems can be viewed in a manner of iteration, recursion and backtracking approach:</p>
            <ul>
                <li><strong>Iteration:</strong> Refers to a class of repetitive tasks such as traversing across arrays in the most efficient manner.</li>
                <li><strong>Recursion:</strong> Solves a problem by solving its smaller subproblems first. Examples include calculating Fibonacci numbers or traversing a tree.</li>
                <li><strong>Backtracking:</strong> Enumerates solutions and removes invalid ones systematically, ideal in solving optimization problems such as N-Queens puzzles.</li>
            </ul>
        </section>
        <section>
            <h2>Space and Time Efficiencies</h2>
            <p>Space and time efficiency are metrics that indicate how efficient an algorithm is in utilizing resources. They are important because:</p>
            <ul>
                <li>With fixed time, the solution must be obtained promptly, crucial in internal systems.</li>
                <li>Optimized space reduces memory requirements, allowing systems with limited resources to operate effectively.</li>
            </ul>
            <p>The <strong>orders of growth</strong> (e.g., O(1), O(n), O(n²)) indicate the rate of growth of an algorithm concerning its input size, enabling analysis of their efficiency for large inputs.</p>
        </section>
        <section>
            <h2>Takeaways From Design Principles, Chapter 2</h2>
            <ul>
                <li><strong>Pruning:</strong> Further faster optimal solutions are reached by reducing unnecessary calculations.</li>
                <li><strong>Hashing:</strong> Enables quick database access by associating keys to locations.</li>
                <li><strong>Union-Find:</strong> Facilitates easier manipulation of disjoint sets, useful in problems like Kruskal's MST.</li>
            </ul>
        </section>
        <section>
            <h2>Hierarchy and Tree Structures</h2>
            <p>Optimized data manipulation is achieved using Trees and their variants such as:</p>
            <ul>
                <li><strong>Binary Search Trees (BSTs):</strong> Simplify searching.</li>
                <li><strong>AVL Trees:</strong> Maintain balance, ensuring logarithmic time for operations.</li>
                <li><strong>Red-Black Trees:</strong> Structured for faster insertion/deletion while remaining approximately balanced.</li>
                <li><strong>Heaps:</strong> Support efficient priority queues.</li>
                <li><strong>Tries:</strong> Compactly manage string data, ideal for prefix-based queries.</li>
            </ul>
        </section>
        <section>
            <h2>Algorithm for Array Queries</h2>
            <p>Structures such as <strong>Segment Trees</strong> and <strong>Fenwick Trees</strong> are applicable for fast range queries and updates. Examples include competitive programming tasks like range sum or minimum queries, where speed is critical.</p>
        </section>
        <section>
            <h2>Trees and Graphs</h2>
            <ul>
                <li><strong>Trees:</strong> Used for hierarchical data such as file systems, are connected and acyclic.</li>
                <li><strong>Graphs:</strong> Handle complex relations, including cyclic and disconnected structures.</li>
                <li><strong>BFS:</strong> Ensures the shortest path in unweighted graphs, while <strong>DFS</strong> explores deeply.</li>
            </ul>
        </section>
        <section>
            <h2>Sorting and Searching Algorithms</h2>
            <ul>
                <li><strong>Sorting:</strong> Merge Sort (divide-and-conquer) and Heap Sort (priority queue) optimize data arrangement.</li>
                <li><strong>Searching:</strong> Binary Search efficiently finds elements in sorted arrays.</li>
            </ul>
        </section>
        <section>
            <h2>Graph Algorithms for Spanning Trees and Shortest Paths</h2>
            <ul>
                <li><strong>Prim's</strong> and <strong>Kruskal's:</strong> Build Minimum Spanning Trees, optimizing connections like road networks.</li>
                <li><strong>Dijkstra’s</strong> and <strong>Bellman-Ford:</strong> Find shortest paths, essential in navigation systems.</li>
            </ul>
        </section>
        <section>
            <h2>Reflections on Broader Questions</h2>
            <ul>
                <li><strong>Efficient Approaches:</strong> Focus on limits set by problem constraints, scalability, and resources.</li>
                <li><strong>Balancing Conflicting Constraints:</strong> Prioritize speed vs. memory based on usage.</li>
                <li><strong>Adapting Solutions:</strong> Example: Adapting BFS to find connected components in a graph.</li>
            </ul>
        </section>
    </main>
    <footer>
        <p>&copy; 2024 Created by Sushant</p>
    </footer>
</body>
</html>
